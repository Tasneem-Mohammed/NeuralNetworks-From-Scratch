{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score"
      ],
      "metadata": {
        "id": "k9GR_M0UgtAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtiEsgs8f48N"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "YvJ0qq0MgNI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDZDhbPsiNrL",
        "outputId": "76980d55-0875-4535-8da0-6c0bf4eb1c16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVxuLQxUifEM",
        "outputId": "db1d1468-7e23-4837-df32-f4150eaa493f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], -1) / 255.0\n",
        "x_test = x_test.reshape(x_test.shape[0], -1) / 255.0"
      ],
      "metadata": {
        "id": "Hb-MMM0VjOhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  checking the shapes:\n",
        "print(\"x_train:\", x_train.shape)\n",
        "print(\"x_test:\", x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hu6Xb7shNXOA",
        "outputId": "caa35461-476e-40b5-b75e-7f6370ada101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train: (60000, 784)\n",
            "x_test: (10000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### MY NOTES ####\n",
        "# our parameters are:\n",
        "# w1: the input of hidden layer\n",
        "#  w2 : the output of hidden layer\n",
        "# b1 : bias of the hidden layer\n",
        "#  b2: bias of the output layer\n",
        "#  act1 is preactivations, act2 : activations\n",
        "#  The bias terms allows the network to shift the activation fn. horizontally\n",
        "#  we have 2 act. functions, Relu is often used in the hidden layers whi;e the softmax in the output oone (& for multi-class classification )"
      ],
      "metadata": {
        "id": "NVt3Ws1ui256"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parameters():\n",
        "    w1 = np.random.rand(10, 784) - 0.5\n",
        "    b1 = np.random.rand(10, 1) - 0.5\n",
        "    w2 = np.random.rand(10, 10) - 0.5\n",
        "    b2 = np.random.rand(10, 1) - 0.5\n",
        "    return w1, b1, w2, b2\n",
        "\n",
        "# RELU (Rectified linear unit activation function):\n",
        "def RELU(z):\n",
        "    return np.maximum(z, 0)   # max z for +ve inputs otherwise 0 (for -ve )\n",
        "\n",
        "def softMax(z):\n",
        "    a = np.exp(z) /sum(np.exp(z))\n",
        "    return a\n"
      ],
      "metadata": {
        "id": "xw15fCmKi22R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forwardPropagation(w1, b1, w2, b2, X):\n",
        "    z1 = w1.dot(X.T) + b1\n",
        "    a1 = RELU(z1)\n",
        "    z2 = w2.dot(a1) + b2\n",
        "    a2 = softMax(z2)\n",
        "    return z1, a1, z2, a2\n",
        "\n",
        "\n",
        "def ReLU_deriv(z):\n",
        "    return (z > 0)\n",
        "\n",
        "\n",
        "def oneHot(Y):\n",
        "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
        "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
        "    one_hot_Y = one_hot_Y.T\n",
        "    return one_hot_Y\n",
        "\n",
        "\n",
        "m = x_train.shape[0]\n",
        "\n",
        "def backwardPropagation(z1, a1, z2, a2, w1, w2, X, Y):\n",
        "    one_hot_Y = oneHot(Y)\n",
        "    dZ2 = a2 - one_hot_Y\n",
        "    dW2 = 1 / m * dZ2.dot(a1.T)\n",
        "    db2 = 1 / m * np.sum(dZ2)\n",
        "    dZ1 = w2.T.dot(dZ2) * ReLU_deriv(z1)\n",
        "    dW1 = 1 / m * dZ1.dot(X)\n",
        "    db1 = 1 / m * np.sum(dZ1)\n",
        "    return dW1, db1, dW2, db2\n"
      ],
      "metadata": {
        "id": "FLjAWGwWAWgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def updateParams(w1, b1, w2, b2, dW1, db1, dW2, db2, alpha):\n",
        "    w1 = w1 - alpha * dW1\n",
        "    b1 = b1 - alpha * db1\n",
        "    w2 = w2 - alpha * dW2\n",
        "    b2 = b2 - alpha * db2\n",
        "    return w1, b1, w2, b2\n",
        "\n",
        "def get_predictions(a2):\n",
        "    return np.argmax(a2, 0)\n",
        "\n",
        "def get_accuracy(predictions, Y):\n",
        "    return np.sum(predictions == Y) / Y.size\n"
      ],
      "metadata": {
        "id": "AbhgmJlYDzH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, Y, alpha, epochs):\n",
        "    w1, b1, w2, b2 = parameters()\n",
        "    m = Y.shape[0]\n",
        "    for i in range(epochs):\n",
        "        z1, a1, z2, a2 = forwardPropagation(w1, b1, w2, b2, X)\n",
        "        dW1, db1, dW2, db2 = backwardPropagation(z1, a1, z2, a2, w1, w2, X, Y)\n",
        "        w1, b1, w2, b2 = updateParams(w1, b1, w2, b2, dW1, db1, dW2, db2, alpha)\n",
        "        if i % 10 == 0:\n",
        "            print(\"epoch number: \", i)\n",
        "            predictions = get_predictions(a2)\n",
        "            print(\"Accuracy:\", get_accuracy(predictions, Y) * 100)\n",
        "    return w1, b1, w2, b2\n"
      ],
      "metadata": {
        "id": "8KbgV6lfb3Hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1, b1, w2, b2 = gradient_descent(x_train, y_train, 0.10, 500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pe-FkFqeq4HX",
        "outputId": "227c2e98-883b-4172-9d33-23c2aaa09e3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch number:  0\n",
            "Accuracy: 7.253333333333334\n",
            "epoch number:  10\n",
            "Accuracy: 22.236666666666665\n",
            "epoch number:  20\n",
            "Accuracy: 32.37\n",
            "epoch number:  30\n",
            "Accuracy: 37.361666666666665\n",
            "epoch number:  40\n",
            "Accuracy: 42.943333333333335\n",
            "epoch number:  50\n",
            "Accuracy: 48.26166666666667\n",
            "epoch number:  60\n",
            "Accuracy: 52.410000000000004\n",
            "epoch number:  70\n",
            "Accuracy: 55.81333333333334\n",
            "epoch number:  80\n",
            "Accuracy: 58.48\n",
            "epoch number:  90\n",
            "Accuracy: 60.97\n",
            "epoch number:  100\n",
            "Accuracy: 63.18333333333334\n",
            "epoch number:  110\n",
            "Accuracy: 65.25166666666667\n",
            "epoch number:  120\n",
            "Accuracy: 67.08666666666666\n",
            "epoch number:  130\n",
            "Accuracy: 68.78999999999999\n",
            "epoch number:  140\n",
            "Accuracy: 70.30499999999999\n",
            "epoch number:  150\n",
            "Accuracy: 71.63166666666667\n",
            "epoch number:  160\n",
            "Accuracy: 72.88166666666666\n",
            "epoch number:  170\n",
            "Accuracy: 73.99\n",
            "epoch number:  180\n",
            "Accuracy: 75.05\n",
            "epoch number:  190\n",
            "Accuracy: 75.92833333333333\n",
            "epoch number:  200\n",
            "Accuracy: 76.68166666666667\n",
            "epoch number:  210\n",
            "Accuracy: 77.35833333333333\n",
            "epoch number:  220\n",
            "Accuracy: 77.98666666666666\n",
            "epoch number:  230\n",
            "Accuracy: 78.60166666666667\n",
            "epoch number:  240\n",
            "Accuracy: 79.135\n",
            "epoch number:  250\n",
            "Accuracy: 79.63166666666666\n",
            "epoch number:  260\n",
            "Accuracy: 80.03333333333333\n",
            "epoch number:  270\n",
            "Accuracy: 80.415\n",
            "epoch number:  280\n",
            "Accuracy: 80.78333333333333\n",
            "epoch number:  290\n",
            "Accuracy: 81.10333333333334\n",
            "epoch number:  300\n",
            "Accuracy: 81.44500000000001\n",
            "epoch number:  310\n",
            "Accuracy: 81.74\n",
            "epoch number:  320\n",
            "Accuracy: 82.005\n",
            "epoch number:  330\n",
            "Accuracy: 82.28833333333333\n",
            "epoch number:  340\n",
            "Accuracy: 82.59166666666667\n",
            "epoch number:  350\n",
            "Accuracy: 82.82000000000001\n",
            "epoch number:  360\n",
            "Accuracy: 82.99666666666667\n",
            "epoch number:  370\n",
            "Accuracy: 83.17666666666666\n",
            "epoch number:  380\n",
            "Accuracy: 83.37\n",
            "epoch number:  390\n",
            "Accuracy: 83.53833333333334\n",
            "epoch number:  400\n",
            "Accuracy: 83.68166666666667\n",
            "epoch number:  410\n",
            "Accuracy: 83.86166666666666\n",
            "epoch number:  420\n",
            "Accuracy: 84.01333333333334\n",
            "epoch number:  430\n",
            "Accuracy: 84.14500000000001\n",
            "epoch number:  440\n",
            "Accuracy: 84.26333333333334\n",
            "epoch number:  450\n",
            "Accuracy: 84.38\n",
            "epoch number:  460\n",
            "Accuracy: 84.50166666666667\n",
            "epoch number:  470\n",
            "Accuracy: 84.59666666666666\n",
            "epoch number:  480\n",
            "Accuracy: 84.69833333333334\n",
            "epoch number:  490\n",
            "Accuracy: 84.82666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w1, b1, w2, b2 = gradient_descent(x_train, y_train, 0.10, 600)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZUki0MekfaO",
        "outputId": "99a60247-a1af-45d5-9672-786117ffdff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration:  0\n",
            "Accuracy: 10.106666666666667\n",
            "Iteration:  10\n",
            "Accuracy: 21.141666666666666\n",
            "Iteration:  20\n",
            "Accuracy: 26.866666666666667\n",
            "Iteration:  30\n",
            "Accuracy: 34.125\n",
            "Iteration:  40\n",
            "Accuracy: 43.031666666666666\n",
            "Iteration:  50\n",
            "Accuracy: 49.7\n",
            "Iteration:  60\n",
            "Accuracy: 54.779999999999994\n",
            "Iteration:  70\n",
            "Accuracy: 58.70833333333333\n",
            "Iteration:  80\n",
            "Accuracy: 61.809999999999995\n",
            "Iteration:  90\n",
            "Accuracy: 64.345\n",
            "Iteration:  100\n",
            "Accuracy: 66.53833333333333\n",
            "Iteration:  110\n",
            "Accuracy: 68.33500000000001\n",
            "Iteration:  120\n",
            "Accuracy: 69.94500000000001\n",
            "Iteration:  130\n",
            "Accuracy: 71.28333333333333\n",
            "Iteration:  140\n",
            "Accuracy: 72.54666666666667\n",
            "Iteration:  150\n",
            "Accuracy: 73.54833333333333\n",
            "Iteration:  160\n",
            "Accuracy: 74.45166666666667\n",
            "Iteration:  170\n",
            "Accuracy: 75.28833333333334\n",
            "Iteration:  180\n",
            "Accuracy: 76.06166666666667\n",
            "Iteration:  190\n",
            "Accuracy: 76.76833333333335\n",
            "Iteration:  200\n",
            "Accuracy: 77.4\n",
            "Iteration:  210\n",
            "Accuracy: 78.02\n",
            "Iteration:  220\n",
            "Accuracy: 78.515\n",
            "Iteration:  230\n",
            "Accuracy: 79.01166666666667\n",
            "Iteration:  240\n",
            "Accuracy: 79.46666666666667\n",
            "Iteration:  250\n",
            "Accuracy: 79.86833333333333\n",
            "Iteration:  260\n",
            "Accuracy: 80.24166666666666\n",
            "Iteration:  270\n",
            "Accuracy: 80.55\n",
            "Iteration:  280\n",
            "Accuracy: 80.86666666666666\n",
            "Iteration:  290\n",
            "Accuracy: 81.19166666666666\n",
            "Iteration:  300\n",
            "Accuracy: 81.48833333333333\n",
            "Iteration:  310\n",
            "Accuracy: 81.73833333333333\n",
            "Iteration:  320\n",
            "Accuracy: 81.985\n",
            "Iteration:  330\n",
            "Accuracy: 82.24333333333334\n",
            "Iteration:  340\n",
            "Accuracy: 82.45666666666666\n",
            "Iteration:  350\n",
            "Accuracy: 82.63833333333334\n",
            "Iteration:  360\n",
            "Accuracy: 82.905\n",
            "Iteration:  370\n",
            "Accuracy: 83.07166666666667\n",
            "Iteration:  380\n",
            "Accuracy: 83.27166666666666\n",
            "Iteration:  390\n",
            "Accuracy: 83.45166666666667\n",
            "Iteration:  400\n",
            "Accuracy: 83.60166666666666\n",
            "Iteration:  410\n",
            "Accuracy: 83.77166666666666\n",
            "Iteration:  420\n",
            "Accuracy: 83.93333333333334\n",
            "Iteration:  430\n",
            "Accuracy: 84.11\n",
            "Iteration:  440\n",
            "Accuracy: 84.25333333333333\n",
            "Iteration:  450\n",
            "Accuracy: 84.39166666666667\n",
            "Iteration:  460\n",
            "Accuracy: 84.52499999999999\n",
            "Iteration:  470\n",
            "Accuracy: 84.64833333333334\n",
            "Iteration:  480\n",
            "Accuracy: 84.75333333333333\n",
            "Iteration:  490\n",
            "Accuracy: 84.86833333333334\n",
            "Iteration:  500\n",
            "Accuracy: 85.01166666666666\n",
            "Iteration:  510\n",
            "Accuracy: 85.135\n",
            "Iteration:  520\n",
            "Accuracy: 85.25\n",
            "Iteration:  530\n",
            "Accuracy: 85.38833333333334\n",
            "Iteration:  540\n",
            "Accuracy: 85.48833333333333\n",
            "Iteration:  550\n",
            "Accuracy: 85.6\n",
            "Iteration:  560\n",
            "Accuracy: 85.68833333333333\n",
            "Iteration:  570\n",
            "Accuracy: 85.8\n",
            "Iteration:  580\n",
            "Accuracy: 85.88833333333334\n",
            "Iteration:  590\n",
            "Accuracy: 86.00833333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test(x_test, y_test, w1, b1, w2, b2):\n",
        "    z1, a1, z2, a2 = forwardPropagation(w1, b1, w2, b2, x_test)\n",
        "    predictions = get_predictions(a2)\n",
        "    acc = get_accuracy(predictions, y_test)\n",
        "    confusion_mat = confusion_matrix(y_test, predictions)\n",
        "    return acc, confusion_mat\n",
        "\n",
        "# w1, b1, w2, b2 = gradient_descent(X_train, Y_train, 0.10, 600)\n",
        "acc, confusion_mat = test(x_test, y_test, w1, b1, w2, b2)\n",
        "print(\"Test Accuracy:\", acc*100, '%')\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkX0vNDPlL6m",
        "outputId": "f46b37b0-e779-4221-d5b1-6e5fcc529578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 85.39999999999999 %\n",
            "Confusion Matrix:\n",
            "[[ 935    0    7    7    1   18    7    1    3    1]\n",
            " [   0 1090    4    6    1    3    4    1   25    1]\n",
            " [  15   18  858   34   16    2   23    9   49    8]\n",
            " [   5    3   34  856    1   42    1   25   35    8]\n",
            " [   4    1   10    1  843    1   21    0   18   83]\n",
            " [  27    5   13   55    8  661   26   11   77    9]\n",
            " [  14    3   19    5   18   17  873    0    8    1]\n",
            " [   4   18   24   13    7    2    0  865    7   88]\n",
            " [  10   19   17   44   23   54   18    9  750   30]\n",
            " [   8    2    2   16   77   20    2   58   15  809]]\n"
          ]
        }
      ]
    }
  ]
}